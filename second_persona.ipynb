{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config and def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, math, time, datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "from numpy.random import *\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.spatial import distance as kld_dist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##### directories #####\n",
    "add_eeg_dir = f'../../../datasets_ro/2306/2306_elan/preprocessing/11_add_Transcrip_to_IM' \n",
    "subject_ID_csv_list = sorted(os.listdir(f'{add_eeg_dir}'))\n",
    "subject_ID_list = [i.removesuffix('.csv') for i in subject_ID_csv_list]\n",
    "\n",
    "##### prep df and label #####\n",
    "all_df = pd.DataFrame()\n",
    "for subject_ID_csv in subject_ID_csv_list:\n",
    "    subject_ID = subject_ID_csv[:-4]\n",
    "    each_subject_df = pd.read_table(f'{add_eeg_dir}/{subject_ID_csv}', sep='\\t', header=0)\n",
    "    all_df = pd.concat([all_df, each_subject_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "SS_score_df = all_df['self-reported sentiment']\n",
    "SS_ternary_ar = np.where(SS_score_df >= 5, 2, np.where(SS_score_df <= 3, 0, 1))\n",
    "all_df.insert(loc=8, column= 'SS_ternary', value= SS_ternary_ar)\n",
    "\n",
    "TS_score_df = all_df.loc[:, 'UI_F1':'UI_M1'].mean(axis=1)\n",
    "TS_ternary_ar = np.where(TS_score_df >= 4.5, 2, np.where(TS_score_df <= 3.5, 0, 1))\n",
    "all_df.insert(loc=10, column= 'TS_ternary', value= TS_ternary_ar)\n",
    "all_df.insert(loc=11, column= 'third-party sentiment', value= TS_score_df)\n",
    "\n",
    "all_subject_df = all_df.copy()\n",
    "\n",
    "##### config #####\n",
    "## TimeSeriesSplit\n",
    "info_dict_tss = {\n",
    "                'n_splits': 3,\n",
    "                'max_train_size': 36,\n",
    "                'valid_test_ratio': 2,\n",
    "                'feat_percentile_list': None, # None, np.arange(12.5, 100, 12.5),\n",
    "                'bin_sect_thres_list': [1], # [1], None, ### power_of_bin < valid_value\n",
    "                'bin_sect_thres_v2_list': [1], # [1], None, ### power_of_bin > valid_value\n",
    "                'valid_target': 'bin_sect_thres_v2', # 'NONE', 'random', 'corr', 'feat_percentile', 'bin_sect_thres', 'bin_sect_thres_v2'\n",
    "                'best_valid_value': None,\n",
    "                'open_close_config': 'open', # None, 'open', 'close', 'both'\n",
    "                'feat_sect': False  # True or False\n",
    "                }\n",
    "\n",
    "## configs == LREC2024\n",
    "info_dict_svm = {\n",
    "                'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                'epsilon': [0, 0.5, 1],\n",
    "                'kernel': 'linear',\n",
    "                'scoring': 'neg_mean_absolute_error',\n",
    "                }\n",
    "\n",
    "rep_exp = 1*info_dict_tss['n_splits']\n",
    "                 \n",
    "### modalities and combination ###\n",
    "validation_method = 'Time_Series_Split'\n",
    "\n",
    "feat_collections_df = pd.DataFrame(\n",
    "                data=[{'modal_name': 'BAU',   'sf_name': 'BAU_000',               'ef_name': 'BAU_767'},\n",
    "                      {'modal_name': 'A',     'sf_name': 'pcm_RMSenergy_sma_max', 'ef_name': 'F0_sma_de_kurtosis'},\n",
    "                      {'modal_name': 'V',     'sf_name': '17_acceleration_max',   'ef_name': 'AU45_c_mean'},\n",
    "                      {'modal_name': 'P',     'sf_name': 'EDA_mean',              'ef_name': 'EDA_gsr'},\n",
    "                      {'modal_name': 'IM',    'sf_name': 'IM_00',                 'ef_name': 'IM_44'},\n",
    "                      ],\n",
    "                       index=None)\n",
    "T_modal_name = 'BAU'\n",
    "A_modal_name = 'A'\n",
    "V_modal_name = 'V'\n",
    "P_modal_name = 'P'\n",
    "B_modal_name = 'IM'\n",
    "\n",
    "modality_list = [T_modal_name, A_modal_name, V_modal_name, P_modal_name, B_modal_name]\n",
    "#modality_list = [T_modal_name, A_modal_name, B_modal_name]\n",
    "\n",
    "combination_list = []\n",
    "for n in range(1,len(modality_list)+1):\n",
    "\tfor comb in itertools.combinations(modality_list, n):\n",
    "\t    combination_list.append(list(comb))\n",
    "\n",
    "dep_list = ['dependent']\n",
    "dummy = '../ML_results/dummy'\n",
    "task_list = ['reg']\n",
    "eval_list = [['MAE', 'R2', 'Rp', 'Rs']]\n",
    "label_name_list = ['self-reported sentiment'] #['SS_ternary']\n",
    "ml_model_name_list = ['SVM']\n",
    "#combination_list = [['BAU'], ['A'], ['V'], ['P'], [B_modal_name]]  # [['BAU'], ['A'], ['V'], ['P'], [B_modal_name]]\n",
    "\n",
    "print(combination_list)\n",
    "\n",
    "##### functions #####\n",
    "def own_prediction_reg(X_train, X_valid, X_test, y_train, y_valid, y_test, ml_mod, info_dict):\n",
    "        \n",
    "    if ml_mod == 'SVM':\n",
    "        \n",
    "        kernel = info_dict['kernel']\n",
    "        C_list = info_dict['C']\n",
    "        epsilon_list = info_dict['epsilon']\n",
    "        scoring = info_dict['scoring']\n",
    "\n",
    "        valid_mae = None\n",
    "        best_valid_mae = 9999\n",
    "        valid_best_C = None\n",
    "        valid_best_epsilon = None\n",
    "        for C in C_list:\n",
    "            for epsilon in epsilon_list:\n",
    "                regr = SVR(kernel=kernel, C=C, epsilon=epsilon, max_iter=1000)\n",
    "                regr.fit(X_train, y_train)\n",
    "                y_valid_pred = regr.predict(X_valid)\n",
    "                y_valid_pred = np.where(y_valid_pred < 1, 1, y_valid_pred) # 外れ値の補正\n",
    "                y_valid_pred = np.where(y_valid_pred > 7, 7, y_valid_pred) # 外れ値の補正\n",
    "                \n",
    "                if scoring == 'neg_mean_absolute_error':\n",
    "                    valid_mae = mean_absolute_error(y_valid_pred, y_valid)\n",
    "                else:\n",
    "                    print('set the scoring')\n",
    "                    sys.exit()\n",
    "                    \n",
    "                if valid_mae < best_valid_mae:\n",
    "                    best_valid_mae = valid_mae\n",
    "                    valid_best_C = C\n",
    "                    valid_best_epsilon = epsilon\n",
    "                    \n",
    "        best_model = SVR(kernel=kernel, C=valid_best_C, epsilon=valid_best_epsilon, max_iter=1000)\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_pred = np.where(y_pred < 1, 1, y_pred) # 外れ値の補正\n",
    "        y_pred = np.where(y_pred > 7, 7, y_pred) # 外れ値の補正\n",
    "        \n",
    "    return y_pred, y_test   \n",
    "\n",
    "def Time_Series_prediction_reg(all_subject_df, feat_collections_df, modal_comb, subject_ID, label_name, rep_exp_num, fusion_method, ml_mod, info_dict):\n",
    "       \n",
    "    train_test_QUE = 'subject_ID == ' + '\\\"' + subject_ID + '\\\"'\n",
    "    exchange_ID_list = all_subject_df.query(train_test_QUE)['exchange_ID'].values\n",
    "    \n",
    "    n_splits = info_dict['n_splits']\n",
    "    max_train_size = info_dict['max_train_size']\n",
    "    tss_a = TimeSeriesSplit(n_splits=n_splits, max_train_size=max_train_size)\n",
    "    \n",
    "    if n_splits == 3:\n",
    "        series_count = 0\n",
    "        for train_ex, val_tes_ex in tss_a.split(exchange_ID_list):\n",
    "            series_count += 1\n",
    "            if rep_exp_num in [1, 4, 7] and series_count == 1:\n",
    "                train_list = list(exchange_ID_list[train_ex])\n",
    "                val_tes_list = list(exchange_ID_list[val_tes_ex])\n",
    "            elif rep_exp_num in [2, 5, 8] and series_count == 2:\n",
    "                train_list = list(exchange_ID_list[train_ex])\n",
    "                val_tes_list = list(exchange_ID_list[val_tes_ex])\n",
    "            elif rep_exp_num in [3, 6, 9] and series_count == 3:\n",
    "                train_list = list(exchange_ID_list[train_ex])\n",
    "                val_tes_list = list(exchange_ID_list[val_tes_ex])\n",
    "            else:\n",
    "                pass\n",
    "                       \n",
    "    train_all_df = all_subject_df.query(train_test_QUE).query('exchange_ID == @train_list')\n",
    "    val_tes_all_df = all_subject_df.query(train_test_QUE).query('exchange_ID == @val_tes_list')\n",
    "\n",
    "    valid_length = len(val_tes_all_df) // info_dict['valid_test_ratio']\n",
    " \n",
    "    valid_all_df = val_tes_all_df.iloc[:valid_length, :]\n",
    "    test_all_df = val_tes_all_df.iloc[valid_length:, :]\n",
    "    \n",
    "    tmp_X_train_tn = []\n",
    "    tmp_X_valid_tn = []\n",
    "    tmp_X_test_tn = []\n",
    "    for modal_name in modal_comb:\n",
    "        \n",
    "        sf_name = feat_collections_df.query('modal_name == @modal_name')['sf_name'].iloc[-1]\n",
    "        ef_name = feat_collections_df.query('modal_name == @modal_name')['ef_name'].iloc[-1]\n",
    "        \n",
    "        X_train_ar = train_all_df.loc[:, sf_name:ef_name].reset_index(drop=True).values\n",
    "        X_valid_ar = valid_all_df.loc[:, sf_name:ef_name].reset_index(drop=True).values\n",
    "        X_test_ar = test_all_df.loc[:, sf_name:ef_name].reset_index(drop=True).values\n",
    "        y_train = train_all_df.loc[:, label_name].reset_index(drop=True).values\n",
    "        y_valid = valid_all_df.loc[:, label_name].reset_index(drop=True).values\n",
    "        y_test = test_all_df.loc[:, label_name].reset_index(drop=True).values\n",
    "        \n",
    "        if (info_dict['valid_target'] != 'NONE') and modal_name  == 'IM': #modal_comb[0]  == 'IM':\n",
    "            \n",
    "            print('IM_custimized')\n",
    "            \n",
    "            if info_dict['valid_target'] in ['feat_percentile', 'bin_sect_thres', 'bin_sect_thres_v2']:\n",
    "                \n",
    "                all_open_close_pxx_df = pd.read_csv(f'../../project-ACII2024/rest_and_btw_log/1701767293/resting_session/all_open_close_pxx_df.csv', header=0)\n",
    "                all_recall_pxx_df = pd.read_csv(f'../../project-ACII2024/rest_and_btw_log/1703138526/recall_session/all_recall_pxx_df.csv', header=0)\n",
    "                \n",
    "                all_open_close_pxx_df_2306M2002 = pd.read_csv(f'../../project-ACII2024/rest_and_btw_log/1706949098/resting_session/all_open_close_pxx_df_2306M2002.csv', header=0)\n",
    "                all_open_close_pxx_df = pd.concat([all_open_close_pxx_df,all_open_close_pxx_df_2306M2002], axis=0).reset_index(drop=True)\n",
    "                \n",
    "                tmp_QUE = 'subject_ID == ' + '\\\"' + subject_ID + '\\\"'\n",
    "                \n",
    "                if info_dict['open_close_config'] == 'both':\n",
    "                    \n",
    "                    subject_open_close_df = all_open_close_pxx_df.query(tmp_QUE).loc[:, '2':'46'].reset_index(drop=True)\n",
    "                    subject_open_close_df = subject_open_close_df.div(subject_open_close_df.sum(axis=1), axis=0)\n",
    "                    \n",
    "                elif info_dict['open_close_config'] == 'open':\n",
    "                    \n",
    "                    subject_open_df = all_open_close_pxx_df[all_open_close_pxx_df[\"ex_ID\"].str.contains(\"open\")]           \n",
    "                    subject_open_df = subject_open_df.query(tmp_QUE).loc[:, '2':'46'].reset_index(drop=True)\n",
    "                    subject_open_close_df = subject_open_df.div(subject_open_df.sum(axis=1), axis=0)\n",
    "                    \n",
    "                elif info_dict['open_close_config'] == 'close':\n",
    "                    \n",
    "                    subject_close_df = all_open_close_pxx_df[all_open_close_pxx_df[\"ex_ID\"].str.contains(\"close\")]\n",
    "                    subject_close_df = subject_close_df.query(tmp_QUE).loc[:, '2':'46'].reset_index(drop=True)\n",
    "                    subject_open_close_df = subject_close_df.div(subject_close_df.sum(axis=1), axis=0)\n",
    "                    \n",
    "                elif info_dict['open_close_config'] is None:\n",
    "                    \n",
    "                    pass\n",
    "                \n",
    "                else:\n",
    "                    print('open_close_config error')\n",
    "                    sys.exit()\n",
    "                        \n",
    "                subject_recall_df = all_recall_pxx_df.query(tmp_QUE).loc[:, '2':'46'].reset_index(drop=True)\n",
    "            \n",
    "            valid_target = info_dict['valid_target']\n",
    "            #if (subject_ID != '2306M2002') or (subject_ID == '2306M2002' and valid_target not in ['feat_percentile', 'bin_sect_thres']):\n",
    "                \n",
    "            best_valid_value = None\n",
    "            valid_mae = None\n",
    "            best_valid_mae = 9999\n",
    "            \n",
    "            if valid_target in ['random', 'corr', 'feat_percentile']:\n",
    "                valid_list = info_dict['feat_percentile_list']\n",
    "            elif valid_target == 'bin_sect_thres' or valid_target == 'bin_sect_thres_v2':\n",
    "                valid_list = info_dict[f'{valid_target}_list']\n",
    "            else:\n",
    "                print('valid_target error')\n",
    "                sys.exit()\n",
    "                \n",
    "            for valid_value in valid_list:\n",
    "                \n",
    "                tmp_tmp_X_train_tn = []\n",
    "                tmp_tmp_X_valid_tn = []\n",
    "                tmp_tmp_X_test_tn = []\n",
    "                \n",
    "                tmp_X_train_ar = X_train_ar.copy()\n",
    "                tmp_X_valid_ar = X_valid_ar.copy()\n",
    "                tmp_X_test_ar = X_test_ar.copy()\n",
    "                \n",
    "                if valid_target in ['feat_percentile', 'bin_sect_thres', 'bin_sect_thres_v2']:\n",
    "                    tmp_X_train_ar, tmp_X_valid_ar, tmp_X_test_ar = norm_based_correction(tmp_X_train_ar, tmp_X_valid_ar, tmp_X_test_ar,\n",
    "                                                                                        subject_open_close_df, subject_recall_df,\n",
    "                                                                                        valid_value, info_dict) # valid\n",
    "                elif valid_target in ['corr', 'random']:\n",
    "                    tmp_X_train_ar, tmp_X_valid_ar, tmp_X_test_ar = feat_sect_corr(tmp_X_train_ar, tmp_X_valid_ar, tmp_X_test_ar, y_train,\n",
    "                                                                                    valid_value, False, info_dict) # valid\n",
    "                else:\n",
    "                    print('valid_target error')\n",
    "                    sys.exit()\n",
    "                \n",
    "                mean_tmp = np.nanmean(tmp_X_train_ar, axis=0).copy()\n",
    "                std_tmp = np.nanstd(tmp_X_train_ar, axis=0, ddof=1).copy()\n",
    "                tmp_X_train_ar = (tmp_X_train_ar - mean_tmp) / std_tmp\n",
    "                tmp_X_valid_ar = (tmp_X_valid_ar - mean_tmp) / std_tmp\n",
    "                tmp_X_test_ar = (tmp_X_test_ar - mean_tmp) / std_tmp\n",
    "                    \n",
    "                pd.DataFrame(tmp_X_train_ar)[pd.DataFrame(tmp_X_train_ar).abs() > 1e+100] = 0 # substitution for bug based on openSMILE F0_sma_min = 0 in all samples\n",
    "                pd.DataFrame(tmp_X_valid_ar)[pd.DataFrame(tmp_X_valid_ar).abs() > 1e+100] = 0 \n",
    "                pd.DataFrame(tmp_X_test_ar)[pd.DataFrame(tmp_X_test_ar).abs() > 1e+100] = 0\n",
    "                \n",
    "                tmp_tmp_X_train_tn.append(np.nan_to_num(tmp_X_train_ar, nan=0)) # openSMILE F0_sma_min = 0 in all samples\n",
    "                tmp_tmp_X_valid_tn.append(np.nan_to_num(tmp_X_valid_ar, nan=0))\n",
    "                tmp_tmp_X_test_tn.append(np.nan_to_num(tmp_X_test_ar, nan=0))\n",
    "                \n",
    "                X_train = tmp_tmp_X_train_tn[0]; X_valid = tmp_tmp_X_valid_tn[0]; X_test = tmp_tmp_X_test_tn[0]\n",
    "                                                                                \n",
    "                kernel = info_dict['kernel']\n",
    "                C_list = info_dict['C']\n",
    "                epsilon_list = info_dict['epsilon']\n",
    "                scoring = info_dict['scoring']\n",
    "\n",
    "                for C in C_list:\n",
    "                    for epsilon in epsilon_list:\n",
    "                        regr = SVR(kernel=kernel, C=C, epsilon=epsilon, max_iter=1000)\n",
    "                        regr.fit(X_train, y_train)\n",
    "                        y_valid_pred = regr.predict(X_valid)\n",
    "                        y_valid_pred = np.where(y_valid_pred < 1, 1, y_valid_pred) # 外れ値の補正\n",
    "                        y_valid_pred = np.where(y_valid_pred > 7, 7, y_valid_pred) # 外れ値の補正\n",
    "                        \n",
    "                        if scoring == 'neg_mean_absolute_error':\n",
    "                            valid_mae = mean_absolute_error(y_valid_pred, y_valid)\n",
    "                        else:\n",
    "                            print('set the scoring')\n",
    "                            sys.exit()\n",
    "                            \n",
    "                        if valid_mae < best_valid_mae:\n",
    "                            best_valid_mae = valid_mae\n",
    "                            best_valid_value = valid_value\n",
    "            \n",
    "            print(f'best_{valid_target}={best_valid_value}')\n",
    "            info_dict[f'best_{valid_target}'] = best_valid_value\n",
    "            if valid_target in ['feat_percentile', 'bin_sect_thres', 'bin_sect_thres_v2']:        \n",
    "                X_train_ar, X_valid_ar, X_test_ar = norm_based_correction(X_train_ar, X_valid_ar, X_test_ar,\n",
    "                                                                        subject_open_close_df, subject_recall_df,\n",
    "                                                                        best_valid_value, info_dict) # decided valid_value\n",
    "            elif valid_target in ['corr', 'random']:\n",
    "                X_train_ar, X_valid_ar, X_test_ar = feat_sect_corr(X_train_ar, X_valid_ar, X_test_ar, y_train,\n",
    "                                                                    best_valid_value, True, info_dict) # decided feat_percentile\n",
    "                \n",
    "            else:\n",
    "                print('valid_target error')\n",
    "                sys.exit()\n",
    "            \n",
    "        else:\n",
    "            print('IM with \\'NONE\\' or other modality')\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        if modal_name in ['BAU']:\n",
    "            pass\n",
    "        elif modal_name in ['A', 'V', 'P', 'IM']:\n",
    "            mean_tmp = np.nanmean(X_train_ar, axis=0).copy()\n",
    "            std_tmp = np.nanstd(X_train_ar, axis=0, ddof=1).copy()\n",
    "            X_train_ar = (X_train_ar - mean_tmp) / std_tmp\n",
    "            X_valid_ar = (X_valid_ar - mean_tmp) / std_tmp\n",
    "            X_test_ar = (X_test_ar - mean_tmp) / std_tmp\n",
    "        else:\n",
    "            print(f'{modal_name} does not Normalize.')\n",
    "            sys.exit()\n",
    "            \n",
    "        pd.DataFrame(X_train_ar)[pd.DataFrame(X_train_ar).abs() > 1e+100] = 0 # substitution for bug based on openSMILE F0_sma_min = 0 in all samples\n",
    "        pd.DataFrame(X_valid_ar)[pd.DataFrame(X_valid_ar).abs() > 1e+100] = 0 \n",
    "        pd.DataFrame(X_test_ar)[pd.DataFrame(X_test_ar).abs() > 1e+100] = 0\n",
    "        \n",
    "        tmp_X_train_tn.append(np.nan_to_num(X_train_ar, nan=0)) # openSMILE F0_sma_min = 0 in all samples\n",
    "        tmp_X_valid_tn.append(np.nan_to_num(X_valid_ar, nan=0)) \n",
    "        tmp_X_test_tn.append(np.nan_to_num(X_test_ar, nan=0))\n",
    "        \n",
    "    if fusion_method == 'uni':\n",
    "        \n",
    "        X_train = tmp_X_train_tn[0]; X_valid = tmp_X_valid_tn[0]; X_test = tmp_X_test_tn[0]\n",
    "        \n",
    "    elif fusion_method == 'EF':\n",
    "        \n",
    "        if len(tmp_X_train_tn) == 1:\n",
    "            print('preparation_error')\n",
    "            sys.exit()\n",
    "        \n",
    "        if not info_dict['feat_sect']:\n",
    "        \n",
    "            valid_dummy = tmp_X_test_tn.copy()\n",
    "            \n",
    "            X_train, X_test = early_fusion(tmp_X_train_tn, tmp_X_test_tn, modal_comb)\n",
    "            X_valid, _ = early_fusion(tmp_X_valid_tn, valid_dummy, modal_comb)\n",
    "            \n",
    "        elif info_dict['feat_sect']:\n",
    "            \n",
    "            X_train, X_valid, X_test = modality_selection(tmp_X_train_tn, tmp_X_valid_tn, tmp_X_test_tn, y_train, y_valid, info_dict)\n",
    "                      \n",
    "        else:\n",
    "            print('feat_sect_error')\n",
    "            sys.exit()\n",
    "\n",
    "    else:\n",
    "        print('fusion_method_error')\n",
    "        sys.exit()\n",
    "    \n",
    "    print('X_train shape', np.shape(X_train), 'y_train shape', np.shape(y_train),\n",
    "          'X_valid shape', np.shape(X_valid), 'y_valid shape', np.shape(y_valid),\n",
    "          'X_test shape', np.shape(X_test), 'y_test shape', np.shape(y_test))\n",
    "    info_dict['used_bin_num'] = np.shape(X_train)[1]\n",
    "        \n",
    "    if ml_mod == 'SVM':\n",
    "        \n",
    "        majority_mae = mean_absolute_error(np.ones(len(y_test))*np.mean(y_train), y_test)        \n",
    "        y_pred, y_test = own_prediction_reg(X_train, X_valid, X_test, y_train, y_valid, y_test, ml_mod, info_dict)\n",
    "        \n",
    "    else:\n",
    "        print('learning model')\n",
    "        sys.exit()\n",
    "    \n",
    "    return y_pred, y_test, majority_mae\n",
    "\n",
    "\n",
    "def modality_selection(tmp_X_train_tn, tmp_X_valid_tn, tmp_X_test_tn, y_train, y_valid, info_dict):\n",
    "    \n",
    "    modal_valid_comb = info_dict['modal_comb']\n",
    "    \n",
    "    modal_combination_list = []\n",
    "    for n in range(1,len(modal_valid_comb)+1):\n",
    "        for comb in itertools.combinations(modal_valid_comb, n):\n",
    "            modal_combination_list.append(list(comb))\n",
    "            \n",
    "    comb_len_list = [len(s) for s in modal_combination_list]\n",
    "    comb_index_list = np.arange(0, len(modal_combination_list), 1)\n",
    "    \n",
    "    bimodal_selection_counter = -1\n",
    "    trimodal_selection_counter = -1\n",
    "    valid_mae = None\n",
    "    best_valid_mae = 9999\n",
    "    best_comb_index = None\n",
    "    for modal_valid_comb, comb_len, comb_index in zip(modal_combination_list, comb_len_list, comb_index_list):\n",
    "                \n",
    "        if comb_len == 1:\n",
    "        \n",
    "            X_train = tmp_X_train_tn[comb_index]\n",
    "            X_valid = tmp_X_valid_tn[comb_index]\n",
    "            X_test = tmp_X_test_tn[comb_index]\n",
    "        \n",
    "        elif comb_len == 2:\n",
    "            \n",
    "            continue\n",
    "                        \n",
    "            # if bimodal_selection_counter == -1:\n",
    "         \n",
    "            #     X_train = np.concatenate([tmp_X_train_tn[0], tmp_X_train_tn[1]], 1)\n",
    "            #     X_valid = np.concatenate([tmp_X_valid_tn[0], tmp_X_valid_tn[1]], 1)\n",
    "            #     X_test = np.concatenate([tmp_X_test_tn[0], tmp_X_test_tn[1]], 1)\n",
    "                \n",
    "            #     bimodal_selection_counter = 1\n",
    "                \n",
    "            # elif bimodal_selection_counter == 1:\n",
    "                \n",
    "            #     X_train = np.concatenate([tmp_X_train_tn[0], tmp_X_train_tn[2]], 1)\n",
    "            #     X_valid = np.concatenate([tmp_X_valid_tn[0], tmp_X_valid_tn[2]], 1)\n",
    "            #     X_test = np.concatenate([tmp_X_test_tn[0], tmp_X_test_tn[2]], 1)\n",
    "                \n",
    "            #     bimodal_selection_counter = 2\n",
    "                \n",
    "            # elif bimodal_selection_counter == 2:\n",
    "                \n",
    "            #     X_train = np.concatenate([tmp_X_train_tn[1], tmp_X_train_tn[2]], 1)\n",
    "            #     X_valid = np.concatenate([tmp_X_valid_tn[1], tmp_X_valid_tn[2]], 1)\n",
    "            #     X_test = np.concatenate([tmp_X_test_tn[1], tmp_X_test_tn[2]], 1)\n",
    "                \n",
    "            #     bimodal_selection_counter = 3\n",
    "                \n",
    "            # else:\n",
    "            #     print('bimodal combination error')\n",
    "            #     sys.exit()\n",
    "                \n",
    "        elif comb_len == 3:\n",
    "            \n",
    "            continue\n",
    "            \n",
    "            # if trimodal_selection_counter == -1:\n",
    "         \n",
    "            #     X_train = np.concatenate([tmp_X_train_tn[0], tmp_X_train_tn[1], tmp_X_train_tn[2]], 1)\n",
    "            #     X_valid = np.concatenate([tmp_X_valid_tn[0], tmp_X_valid_tn[1], tmp_X_valid_tn[2]], 1)\n",
    "            #     X_test = np.concatenate([tmp_X_test_tn[0], tmp_X_test_tn[1], tmp_X_test_tn[2]], 1)\n",
    "                \n",
    "            #     trimodal_selection_counter = 1\n",
    "                \n",
    "            # else:\n",
    "            #     print('trimodal combination error')\n",
    "            #     sys.exit()\n",
    "                \n",
    "    \n",
    "        kernel = info_dict['kernel']\n",
    "        C_list = info_dict['C']\n",
    "        epsilon_list = info_dict['epsilon']\n",
    "        scoring = info_dict['scoring']\n",
    "\n",
    "        for C in C_list:\n",
    "            for epsilon in epsilon_list:\n",
    "                regr = SVR(kernel=kernel, C=C, epsilon=epsilon, max_iter=1000)\n",
    "                regr.fit(X_train, y_train)\n",
    "                y_valid_pred = regr.predict(X_valid)\n",
    "                y_valid_pred = np.where(y_valid_pred < 1, 1, y_valid_pred) # 外れ値の補正\n",
    "                y_valid_pred = np.where(y_valid_pred > 7, 7, y_valid_pred) # 外れ値の補正\n",
    "                \n",
    "                if scoring == 'neg_mean_absolute_error':\n",
    "                    valid_mae = mean_absolute_error(y_valid_pred, y_valid)\n",
    "                else:\n",
    "                    print('set the scoring')\n",
    "                    sys.exit()\n",
    "                    \n",
    "                if valid_mae < best_valid_mae:\n",
    "                    best_valid_mae = valid_mae\n",
    "                    best_comb_index = comb_index\n",
    "                    \n",
    "    best_comb = modal_combination_list[best_comb_index]\n",
    "                    \n",
    "    print(f'{len(best_comb)} modality is selected. best_comb = {best_comb}.')\n",
    "    \n",
    "    if len(best_comb) == 1:\n",
    "        \n",
    "        info_dict['best_selected_modal'] = best_comb\n",
    "    \n",
    "        X_train = tmp_X_train_tn[best_comb_index]\n",
    "        X_valid = tmp_X_valid_tn[best_comb_index]\n",
    "        X_test = tmp_X_test_tn[best_comb_index]\n",
    "    \n",
    "    elif len(best_comb) == 2:\n",
    "        \n",
    "        print('method is abortd')\n",
    "        sys.exit()\n",
    "        \n",
    "        # modal_index_1 = modal_combination_list.index([best_comb[0]])\n",
    "        # modal_index_2 = modal_combination_list.index([best_comb[1]])\n",
    "        \n",
    "        # X_train = np.concatenate([tmp_X_train_tn[modal_index_1], tmp_X_train_tn[modal_index_2]], 1)\n",
    "        # X_valid = np.concatenate([tmp_X_valid_tn[modal_index_1], tmp_X_valid_tn[modal_index_2]], 1)\n",
    "        # X_test = np.concatenate([tmp_X_test_tn[modal_index_1], tmp_X_test_tn[modal_index_2]], 1)\n",
    "                       \n",
    "    elif len(best_comb) == 3:\n",
    "        \n",
    "        print('method is abortd')\n",
    "        sys.exit()\n",
    "              \n",
    "        # X_train = np.concatenate([tmp_X_train_tn[0], tmp_X_train_tn[1], tmp_X_train_tn[2]], 1)\n",
    "        # X_valid = np.concatenate([tmp_X_valid_tn[0], tmp_X_valid_tn[1], tmp_X_valid_tn[2]], 1)\n",
    "        # X_test = np.concatenate([tmp_X_test_tn[0], tmp_X_test_tn[1], tmp_X_test_tn[2]], 1)\n",
    "        \n",
    "    else:\n",
    "        print('best_comb_len error')\n",
    "        sys.exit()\n",
    "            \n",
    "    return X_train, X_valid, X_test\n",
    "    \n",
    "\n",
    "def norm_based_correction(X_train_ar, X_valid_ar, X_test_ar,\n",
    "                          subject_open_close_df, subject_recall_df,\n",
    "                          valid_value, info_dict):\n",
    "\n",
    "    recall_change_level_each_bin = subject_recall_df.mean(axis=0) / subject_open_close_df.mean(axis=0)\n",
    "    # max = 4.901 in 2306F4002\n",
    "\n",
    "    del_column_num_list = []\n",
    "    j = 0\n",
    "    for power_of_bin in recall_change_level_each_bin:\n",
    "        \n",
    "        if info_dict['valid_target'] == 'feat_percentile':\n",
    "            if power_of_bin < np.percentile(recall_change_level_each_bin, valid_value):\n",
    "                del_column_num_list.append(j)\n",
    "            else:\n",
    "                pass\n",
    "        elif info_dict['valid_target'] == 'bin_sect_thres':\n",
    "            if power_of_bin < valid_value:\n",
    "                del_column_num_list.append(j)\n",
    "                if len(del_column_num_list) == np.shape(X_train_ar)[-1]:\n",
    "                    del_column_num_list = np.delete(np.arange(0,45,1), int(recall_change_level_each_bin.reset_index(drop=True).idxmax()))\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        # elif info_dict['valid_target'] == 'bin_sect_thres_v2':\n",
    "        #     if power_of_bin > valid_value :\n",
    "        #         del_column_num_list.append(j)\n",
    "        #         if len(del_column_num_list) == np.shape(X_train_ar)[-1]:\n",
    "        #             del_column_num_list = np.delete(np.arange(0,45,1), int(recall_change_level_each_bin.reset_index(drop=True).idxmax()))\n",
    "        #     else:\n",
    "        #         pass\n",
    "        \n",
    "        elif info_dict['valid_target'] == 'bin_sect_thres_v2':\n",
    "            \n",
    "            subject_ID = info_dict['subject_ID']\n",
    "            pred_del_dim = del_dim_num_list_df.query('subject_ID==@subject_ID')['pred_del_dim'].iloc[-1]\n",
    "            #del_dim_num = del_dim_num_list_df.query('subject_ID==@subject_ID')['del_dim_num'].iloc[-1]\n",
    "            \n",
    "            if sorted(recall_change_level_each_bin, reverse=True).index(power_of_bin) < 45 - pred_del_dim :\n",
    "                pass\n",
    "            else:\n",
    "                del_column_num_list.append(j)\n",
    "                if len(del_column_num_list) == np.shape(X_train_ar)[-1]:\n",
    "                    del_column_num_list = np.delete(np.arange(0,45,1), int(recall_change_level_each_bin.reset_index(drop=True).idxmax()))\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        j += 1\n",
    "\n",
    "    correct_X_train_ar = pd.DataFrame(X_train_ar).drop(pd.DataFrame(X_train_ar).columns[del_column_num_list], axis=1).values\n",
    "    correct_X_valid_ar = pd.DataFrame(X_valid_ar).drop(pd.DataFrame(X_valid_ar).columns[del_column_num_list], axis=1).values\n",
    "    correct_X_test_ar = pd.DataFrame(X_test_ar).drop(pd.DataFrame(X_test_ar).columns[del_column_num_list], axis=1).values\n",
    "               \n",
    "    return correct_X_train_ar, correct_X_valid_ar, correct_X_test_ar\n",
    "\n",
    "def early_fusion(tmp_X_train_tn, tmp_X_test_tn, modal_comb):\n",
    "    \n",
    "    for i in range(len(modal_comb)):\n",
    "        if i == 0:\n",
    "            X_train = tmp_X_train_tn[i]\n",
    "            X_test = tmp_X_test_tn[i]\n",
    "        else:          \n",
    "            X_train = np.concatenate([X_train, tmp_X_train_tn[i]], 1)\n",
    "            X_test = np.concatenate([X_test, tmp_X_test_tn[i]], 1)\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def feat_sect_corr(tmp_X_train_ar, tmp_X_valid_ar, tmp_X_test_ar, y_train, valid_value, decision, info_dict):\n",
    "    \n",
    "    if info_dict['valid_target'] == 'corr':\n",
    "    \n",
    "        sect_bin_list_df = pd.DataFrame(columns=['bin', 'corr'])\n",
    "        for one_bin in range(np.shape(tmp_X_train_ar)[1]):\n",
    "            num_and_corr = pd.DataFrame([[one_bin, spearmanr(tmp_X_train_ar[:, one_bin], y_train)[0]]], columns=['bin', 'corr'])\n",
    "            \n",
    "            if spearmanr(tmp_X_train_ar[:, one_bin], y_train)[1] < 0.05:\n",
    "                sect_bin_list_df = pd.concat([sect_bin_list_df, num_and_corr], axis=0).reset_index(drop=True)\n",
    "\n",
    "        origin_sect_bin_list_df = sect_bin_list_df.copy()\n",
    "        sect_bin_list_df = sect_bin_list_df.sort_values('corr', ascending=False)\n",
    "        sect_feat_range = math.ceil(len(sect_bin_list_df)*valid_value/100)\n",
    "        sect_bin_list_df = sect_bin_list_df.iloc[:sect_feat_range, :]\n",
    "        \n",
    "        if len(sect_bin_list_df[sect_bin_list_df['corr'] > 0]) != 0:\n",
    "            sect_bin_list_df = sect_bin_list_df[sect_bin_list_df['corr'] > 0]\n",
    "            sect_feat_bin = np.array(sect_bin_list_df['bin'].values, dtype='int64')\n",
    "            if decision:\n",
    "                print('selected_feat_corr', sect_bin_list_df)\n",
    "        else:\n",
    "            sect_bin_list_df = origin_sect_bin_list_df  # .sort_values('corr', ascending=False).iloc[:25, :] # sect_bin_list_df.iloc[0, :]\n",
    "            sect_feat_bin = np.arange(0,45,1)\n",
    "            if decision:\n",
    "                print('selected_feat_corr', 'there are no pos corr.')\n",
    "    \n",
    "    elif info_dict['valid_target'] == 'random':\n",
    "        sect_feat_bin = choice(np.arange(0, np.shape(tmp_X_train_ar)[1] ,1), math.ceil(np.shape(tmp_X_train_ar)[1]*valid_value/100), replace = False)\n",
    "        #sect_feat_bin = np.arange(0,3,1)   ##### delta     frequency corresponded to IM00-IM02 1 < w < 4\n",
    "        #sect_feat_bin = np.arange(3,6,1)   ##### theta     frequency corresponded to IM03-IM05 4 < w < 7\n",
    "        #sect_feat_bin = np.arange(7,12,1)   ##### alpha    frequency corresponded to IM07-IM11 8 < w < 13\n",
    "        #sect_feat_bin = np.arange(12,29,1) ##### beta      frequency corresponded to IM12-IM28 13 < w < 30\n",
    "        #sect_feat_bin = np.arange(29,45,1) ##### gamma     frequency corresponded to IM29-IM44 30 < w < 45\n",
    "        \n",
    "    else:\n",
    "        print('valid_target error')\n",
    "        sys.exit()\n",
    "    \n",
    "    correct_X_train_ar = tmp_X_train_ar[:, sect_feat_bin]\n",
    "    correct_X_valid_ar = tmp_X_valid_ar[:, sect_feat_bin]\n",
    "    correct_X_test_ar = tmp_X_test_ar[:, sect_feat_bin]\n",
    "    \n",
    "    return correct_X_train_ar, correct_X_valid_ar, correct_X_test_ar\n",
    "\n",
    "\n",
    "\n",
    "def save_pred_and_prob(task_name, y_pred_proba, y_pred, y_true, info_dict):\n",
    "    \n",
    "    if task_name == 'cls':\n",
    "        prob_dir = f'{dummy}/cls_pred_and_prob'\n",
    "        proba_df = pd.DataFrame(y_pred_proba, columns=['pred_low', 'pred_mid', 'pred_high']).copy()\n",
    "    else:\n",
    "        prob_dir = f'{dummy}/reg_pred'\n",
    "        proba_df = pd.DataFrame()\n",
    "        y_pred = pd.DataFrame(y_pred) \n",
    "        \n",
    "    proba_df['y_pred'] = y_pred\n",
    "    proba_df['y_true'] = y_true\n",
    "    \n",
    "    timestr = info_dict['timestr']\n",
    "    subject_ID = info_dict['subject_ID']\n",
    "    label_name = info_dict['label_name']\n",
    "    modal_comb = info_dict['modal_comb']\n",
    "    ml_mod = info_dict['ml_mod']\n",
    "    fusion_method= info_dict['fusion_method']\n",
    "    rep_exp_num = info_dict['rep_exp_num']\n",
    "    valid_target = info_dict['valid_target']\n",
    "    \n",
    "    if not fusion_method == 'ensemble':\n",
    "        \n",
    "        if modal_comb[-1] == 'IM': \n",
    "            if valid_target == 'NONE':\n",
    "                data_dir = f'{prob_dir}/{timestr}/{subject_ID}/{label_name}/{modal_comb}/{ml_mod}/{fusion_method}'\n",
    "            else:\n",
    "                data_dir = f'{prob_dir}/{timestr}/{subject_ID}/{label_name}/{valid_target}/{ml_mod}/{fusion_method}'\n",
    "        else:\n",
    "            data_dir = f'{prob_dir}/{timestr}/{subject_ID}/{label_name}/{modal_comb}/{ml_mod}/{fusion_method}'\n",
    "        os.makedirs(f'{data_dir}', exist_ok=True)\n",
    "        proba_df.to_csv(f'{data_dir}/rep_exp_num_{rep_exp_num}.csv', index=False)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        ### if prediction value of ensemble is needed, save by below code\n",
    "        # data_dir = f'{prob_dir}/{timestr}/{subject_ID}/{label_name}/{modal_comb}/{ml_mod}/{fusion_method}'\n",
    "        # os.makedirs(f'{data_dir}', exist_ok=True)\n",
    "        # proba_df.to_csv(f'{data_dir}/rep_exp_num_{rep_exp_num}.csv', index=False)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "def save_cls_or_reg(evalist, eval_name_list, info_dict, rep_exp):\n",
    "    \n",
    "    if len(eval_name_list) == 2:\n",
    "        eval_dir = f'{dummy}/cls_acc_and_f1'\n",
    "        for i in range(2):\n",
    "            info_dict[eval_name_list[i]] = evalist[i]\n",
    "    elif len(eval_name_list) == 4:\n",
    "        eval_dir = f'{dummy}/reg_mae_and_corr'\n",
    "        for i in range(4):\n",
    "            info_dict[eval_name_list[i]] = evalist[i]\n",
    "    else:\n",
    "        sys.exit()\n",
    "    \n",
    "    timestr = info_dict['timestr']\n",
    "    os.makedirs(f'{eval_dir}/{timestr}', exist_ok=True)\n",
    "    try:\n",
    "        detail_df = pd.read_csv(f'{eval_dir}/{timestr}/detail.csv', header=0)\n",
    "        detail_df = pd.concat([detail_df, pd.json_normalize(info_dict)], axis=0).reset_index(drop=True)\n",
    "        detail_df.to_csv(f'{eval_dir}/{timestr}/detail.csv', index=False)\n",
    "    except:\n",
    "        pd.json_normalize(info_dict).to_csv(f'{eval_dir}/{timestr}/detail.csv', index=False)\n",
    "        detail_df = pd.read_csv(f'{eval_dir}/{timestr}/detail.csv', header=0)\n",
    "    \n",
    "    if info_dict['dependency'] == 'independent':\n",
    "        if info_dict['subject_ID'] == subject_ID_list[-1]:\n",
    "            del info_dict['subject_ID'], info_dict['elapsed']\n",
    "            for eval_name in eval_name_list:\n",
    "                info_dict[eval_name] = np.nanmean(detail_df[eval_name].iloc[-len(subject_ID_list):].values) # inter subject average\n",
    "                print(f'subject_mean_{eval_name}:', np.round(info_dict[eval_name], decimals=3), end='')\n",
    "                print()\n",
    "            try:\n",
    "                tmp_df = pd.read_csv(f'{eval_dir}/{timestr}/tmp.csv', header=0)\n",
    "                tmp_df = pd.concat([tmp_df, pd.json_normalize(info_dict)], axis=0).reset_index(drop=True)\n",
    "                tmp_df.to_csv(f'{eval_dir}/{timestr}/tmp.csv', index=False)\n",
    "            except:\n",
    "                pd.json_normalize(info_dict).to_csv(f'{eval_dir}/{timestr}/tmp.csv', index=False)\n",
    "        \n",
    "            if info_dict['rep_exp_num'] == rep_exp:\n",
    "                del info_dict['rep_exp_num']\n",
    "                tmp_df = pd.read_csv(f'{eval_dir}/{timestr}/tmp.csv', header=0) # inter run-num average\n",
    "                for eval_name in eval_name_list:\n",
    "                    info_dict[eval_name] = np.nanmean(tmp_df[eval_name].iloc[-rep_exp:].values)\n",
    "                    print()\n",
    "                    print(f'rep_mean_{eval_name}:', np.round(info_dict[eval_name], decimals=3), end='')\n",
    "                    print()\n",
    "                    if rep_exp == 1:\n",
    "                        info_dict[f'{eval_name}_SD'] = np.nan\n",
    "                    else:\n",
    "                        info_dict[f'{eval_name}_SD'] = np.std(tmp_df[eval_name].iloc[-rep_exp:].values, ddof=1)\n",
    "                try:\n",
    "                    summary_df = pd.read_csv(f'{eval_dir}/{timestr}/summary.csv', header=0)\n",
    "                    summary_df = pd.concat([summary_df, pd.json_normalize(info_dict)], axis=0).reset_index(drop=True)\n",
    "                    summary_df.to_csv(f'{eval_dir}/{timestr}/summary.csv', index=False)\n",
    "                except:\n",
    "                    pd.json_normalize(info_dict).to_csv(f'{eval_dir}/{timestr}/summary.csv', index=False)\n",
    "                    \n",
    "    if info_dict['dependency'] == 'dependent':\n",
    "        if info_dict['rep_exp_num'] == rep_exp:\n",
    "            del info_dict['rep_exp_num'] #, info_dict['n_epochs'], info_dict['lr']\n",
    "            for eval_name in eval_name_list:\n",
    "                info_dict[eval_name] = np.nanmean(detail_df[eval_name].iloc[-rep_exp:].values) # inter run-num average\n",
    "                info_dict['majority_mae'] = np.nanmean(detail_df['majority_mae'].iloc[-rep_exp:].values) # inter run-num average\n",
    "                print(f'rep_mean_{eval_name}:', np.round(info_dict[eval_name], decimals=3), end='')\n",
    "                print()\n",
    "                if rep_exp == 1:\n",
    "                    info_dict[f'{eval_name}_SD'] = np.nan\n",
    "                else:\n",
    "                    info_dict[f'{eval_name}_SD'] = np.nanstd(detail_df[eval_name].iloc[-rep_exp:].values, ddof=1)\n",
    "            try:\n",
    "                tmp_df = pd.read_csv(f'{eval_dir}/{timestr}/tmp.csv', header=0)\n",
    "                tmp_df = pd.concat([tmp_df, pd.json_normalize(info_dict)], axis=0).reset_index(drop=True)\n",
    "                tmp_df.to_csv(f'{eval_dir}/{timestr}/tmp.csv', index=False)\n",
    "            except:\n",
    "                pd.json_normalize(info_dict).to_csv(f'{eval_dir}/{timestr}/tmp.csv', index=False)\n",
    "                \n",
    "            if info_dict['subject_ID'] == subject_ID_list[-1]:\n",
    "                del info_dict['elapsed'], info_dict['subject_ID']\n",
    "                tmp_df = pd.read_csv(f'{eval_dir}/{timestr}/tmp.csv', header=0)\n",
    "                for eval_name in eval_name_list:\n",
    "                    info_dict[eval_name] = np.nanmean(tmp_df[eval_name].iloc[-len(subject_ID_list):].values) # inter subject average\n",
    "                    info_dict[f'{eval_name}_SD'] = np.nanstd(tmp_df[eval_name].iloc[-len(subject_ID_list):].values) # inter subject SD\n",
    "                    info_dict['majority_mae'] = np.nanmean(tmp_df['majority_mae'].iloc[-len(subject_ID_list):].values) # inter subject mjr_mae\n",
    "                    print()\n",
    "                    print(f'subject_mean_{eval_name}:', np.round(info_dict[eval_name], decimals=3), end='')\n",
    "                    \n",
    "                    print()\n",
    "                try:\n",
    "                    summary_df = pd.read_csv(f'{eval_dir}/{timestr}/summary.csv', header=0)\n",
    "                    summary_df = pd.concat([summary_df, pd.json_normalize(info_dict)], axis=0).reset_index(drop=True)\n",
    "                    summary_df.to_csv(f'{eval_dir}/{timestr}/summary.csv', index=False)\n",
    "                except:\n",
    "                    pd.json_normalize(info_dict).to_csv(f'{eval_dir}/{timestr}/summary.csv', index=False)\n",
    "                    \n",
    "                mae_list.append(np.round(info_dict['MAE'], decimals=2))\n",
    "                scorr_list.append(np.round(info_dict['Rs'], decimals=2))    \n",
    "                print(mae_list)\n",
    "                print(scorr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cla and reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_list = []\n",
    "scorr_list = []\n",
    "start_time = time.time()\n",
    "timestr = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "### parameter serach\n",
    "# for i in np.arange(0, 5, 0.025):\n",
    "#     info_dict_tss['bin_sect_thres_list'] = [i]\n",
    "\n",
    "### methods comparison\n",
    "# for valid_target in ['NONE', 'random', 'corr', 'bin_sect_thres']:\n",
    "#     info_dict_tss['valid_target'] = valid_target\n",
    "\n",
    "for dependency in dep_list:\n",
    "    for task_name, eval_name_list, label_name in zip(task_list, eval_list, label_name_list):\n",
    "        for modal_comb in combination_list:\n",
    "            # if (info_dict_tss['valid_target'] != 'NONE') and (modal_comb in [['BAU'], ['A'], ['V'], ['P']]): # use if running both TAVP and IM with each method (None, Rand, etc.)\n",
    "            #     continue\n",
    "            for ml_mod in ml_model_name_list:\n",
    "                if ml_mod in ['SVM', 'RF', 'NB', 'neural']:\n",
    "                    fusion_method_list = ['uni','EF']\n",
    "                else:\n",
    "                    fusion_method_list = ['uni', 'EF', 'LF']\n",
    "                for fusion_method in fusion_method_list:\n",
    "                    if len(modal_comb) != 1 and fusion_method == 'uni':\n",
    "                        continue    \n",
    "                    elif len(modal_comb) == 1 and fusion_method == 'EF':\n",
    "                        continue\n",
    "                    elif len(modal_comb) == 1 and fusion_method == 'LF':\n",
    "                        continue\n",
    "                    \n",
    "                    # #####\n",
    "                    # elif len(modal_comb) == 2:\n",
    "                    #     continue\n",
    "                    # #####\n",
    "                    \n",
    "                    else:\n",
    "                        pass\n",
    "                    \n",
    "                    if dependency == 'independent':\n",
    "                        loop_1 = np.arange(0, rep_exp)\n",
    "                        loop_2 = subject_ID_list\n",
    "                    elif dependency == 'dependent':\n",
    "                        loop_1 = subject_ID_list\n",
    "                        loop_2 = np.arange(0, rep_exp)\n",
    "                    \n",
    "                    for loop_1_element in loop_1:\n",
    "                        if dependency == 'independent':\n",
    "                            rep_exp_num = loop_1_element\n",
    "                            rep_exp_num += 1\n",
    "                        else:\n",
    "                            subject_ID = loop_1_element\n",
    "                        \n",
    "                        for loop_2_element in loop_2:\n",
    "                            if dependency == 'independent':\n",
    "                                subject_ID = loop_2_element\n",
    "                            else:\n",
    "                                rep_exp_num = loop_2_element\n",
    "                                rep_exp_num += 1\n",
    "                                \n",
    "                            if task_name == 'cls':\n",
    "                                batch_size = cls_batch_size\n",
    "                                #n_epochs = cls_n_epochs\n",
    "                                #learning_rate = cls_learning_rate\n",
    "                            else:\n",
    "                                batch_size = None\n",
    "                                #learning_rate = reg_learning_rate\n",
    "                                \n",
    "                            info_dict = {'subject_ID': subject_ID, 'dependency': dependency, 'task_name': task_name, 'label_name': label_name, 'modal_comb': modal_comb,\n",
    "                                    'ml_mod': ml_mod,'fusion_method': fusion_method, 'rep_exp_num': rep_exp_num, 'f1_setting': 'weighted',\n",
    "                                    'timestr': timestr, 'elapsed': time.time()-start_time}\n",
    "                            info_dict =  dict(**info_dict, **info_dict_svm, **info_dict_tss)\n",
    "                            \n",
    "                            if validation_method == 'Time_Series_Split':\n",
    "                                pass\n",
    "                                \n",
    "                            print(subject_ID, info_dict_tss['valid_target'], 'rep', rep_exp_num, modal_comb)\n",
    "                                                            \n",
    "                            if task_name == 'reg':\n",
    "                                \n",
    "                                if validation_method == 'Time_Series_Split':\n",
    "                                    y_pred, y_test, majority_mae = Time_Series_prediction_reg(all_subject_df, feat_collections_df, modal_comb, subject_ID, label_name, rep_exp_num, fusion_method, ml_mod, info_dict)\n",
    "                                    info_dict['majority_mae'] = majority_mae\n",
    "                                else:\n",
    "                                    y_pred, y_test = own_prediction_reg(X_train, X_test, y_train, y_test, ml_mod, info_dict)\n",
    "                                y_true = y_test.copy()\n",
    "                                save_pred_and_prob(task_name, None, y_pred, y_true, info_dict)\n",
    "                                \n",
    "                                mae = mean_absolute_error(y_true, y_pred)\n",
    "                                if len(np.unique(y_true)) == 1:\n",
    "                                    r2, rp, rq = np.nan, np.nan, np.nan\n",
    "                                else:\n",
    "                                    r2 = r2_score(y_true, y_pred)\n",
    "                                    rp = pearsonr(y_true, y_pred)[0]\n",
    "                                    rs = spearmanr(y_true, y_pred)[0]\n",
    "                                    \n",
    "                                reg_evalist = [mae, r2, rp, rs]\n",
    "                                print('test_MAE:', np.round(mae, decimals=3), f'test_R2:', np.round(r2, decimals=3), end=' ')\n",
    "                                print('test_Rp:', np.round(rp, decimals=3), f'test_Rs:', np.round(rs, decimals=3))\n",
    "                                print()\n",
    "                                save_cls_or_reg(reg_evalist, eval_name_list, info_dict, rep_exp)\n",
    "                    print()\n",
    "                    \n",
    "print(timestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power_of_bin < valid_value=0.5     0.87, 0.19\n",
    "# power_of_bin < valid_value=1.0     0.82, 0.21\n",
    "# power_of_bin < valid_value=2.0     0.84, 0.17\n",
    "\n",
    "# power_of_bin > valid_value=0.5     0.91, 0.12\n",
    "# power_of_bin > valid_value=1.0     0.90, 0.16\n",
    "# power_of_bin > valid_value=2.0     0.88, 0.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason of threshold settings are refered to \"Threshold_setting_reason.ipynb\" in the same level directori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.precision = 2\n",
    "df = pd.read_csv(f'../ML_results/dummy/reg_mae_and_corr/{timestr}/summary.csv')\n",
    "df = df.reindex(columns=['modal_comb', 'fusion_method', 'MAE', 'Rs'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modal_comb\tfusion_method\t    MAE\t    Rs\n",
    "# 0\t['BAU']\t                    uni\t0.75\t0.29\n",
    "# 1\t['A']\t                    uni\t0.80\t0.35\n",
    "# 2\t['IM']\t                    uni\t0.82\t0.24\n",
    "# 3\t['BAU', 'A']\t            EF\t0.76\t0.32\n",
    "# 4\t['BAU', 'IM']\t            EF\t0.75\t0.30\n",
    "# 5\t['A', 'IM']\t                EF\t0.80\t0.31\n",
    "# 6\t['BAU', 'A', 'IM']\t        EF\t0.76\t0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.precision = 2\n",
    "#df = pd.read_csv(f'../ML_results/dummy/reg_mae_and_corr/{timestr}/detail.csv')\n",
    "df = pd.read_csv(f'/home/katada/Desktop/def_dir/under_def_2nd/paper_result/Multimodal_20240213013057/detail.csv')\n",
    "df = df.reindex(columns=['subject_ID', 'modal_comb', 'best_selected_modal', 'fusion_method', 'MAE', 'Rs']).iloc[270:, :]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of the deleted dimesion in optimized threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_eeg_dir = f'../../../datasets_ro/2306/2306_elan/preprocessing/11_add_Transcrip_to_IM'\n",
    "subject_ID_csv_list = sorted(os.listdir(f'{add_eeg_dir}'))\n",
    "subject_ID_list = [i.removesuffix('.csv') for i in subject_ID_csv_list]\n",
    "\n",
    "# from \"Threshold_setting_reason.ipynb\" in the same level directori\n",
    "threshold_list_df = pd.read_csv(f'../../project-ACII2024/paper_result/Threshold_search_20240210230435/threshold_list.csv', header=0)\n",
    "\n",
    "recall_change_level_each_bin_df = pd.DataFrame()\n",
    "recall_change_level_each_bin_df2 = pd.DataFrame()\n",
    "del_dim_num_list_df = pd.DataFrame()\n",
    "for subject_ID in subject_ID_list:\n",
    "    all_open_close_pxx_df = pd.read_csv(f'../../project-ACII2024/rest_and_btw_log/1701767293/resting_session/all_open_close_pxx_df.csv', header=0)\n",
    "    all_recall_pxx_df = pd.read_csv(f'../../project-ACII2024/rest_and_btw_log/1703138526/recall_session/all_recall_pxx_df.csv', header=0)\n",
    "    \n",
    "    all_open_close_pxx_df_2306M2002 = pd.read_csv(f'../../project-ACII2024/rest_and_btw_log/1706949098/resting_session/all_open_close_pxx_df_2306M2002.csv', header=0)\n",
    "    all_open_close_pxx_df = pd.concat([all_open_close_pxx_df,all_open_close_pxx_df_2306M2002], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    tmp_QUE = 'subject_ID == ' + '\\\"' + subject_ID + '\\\"'\n",
    "                                            \n",
    "    subject_open_df = all_open_close_pxx_df[all_open_close_pxx_df[\"ex_ID\"].str.contains(\"open\")]           \n",
    "    subject_open_df = subject_open_df.query(tmp_QUE).loc[:, '2':'46'].reset_index(drop=True)\n",
    "    subject_open_close_df = subject_open_df.div(subject_open_df.sum(axis=1), axis=0)\n",
    "    \n",
    "    subject_recall_df = all_recall_pxx_df.query(tmp_QUE).loc[:, '2':'46'].reset_index(drop=True)\n",
    "    \n",
    "    recall_change_level_each_bin = subject_recall_df.mean(axis=0) / subject_open_close_df.mean(axis=0)\n",
    "    recall_change_level_each_bin_df = pd.concat([recall_change_level_each_bin_df, pd.DataFrame(recall_change_level_each_bin).T], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    tmp = pd.concat([subject_recall_df.mean(axis=0) , subject_open_close_df.mean(axis=0)], axis=0)\n",
    "    recall_change_level_each_bin_df2 = pd.concat([recall_change_level_each_bin_df2, pd.DataFrame(tmp).T], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    #print(subject_ID, np.round(subject_recall_df.mean(axis=0).sum(), decimals=2), np.round(subject_open_close_df.mean(axis=0).sum(), decimals=2))\n",
    "    \n",
    "    del_column_num_list = []\n",
    "    j = 0\n",
    "    for power_of_bin in recall_change_level_each_bin:\n",
    "        \n",
    "        valid_value = threshold_list_df.query(tmp_QUE)['Corr_max_threshold'].iloc[-1]\n",
    "        \n",
    "        if power_of_bin < valid_value:\n",
    "            del_column_num_list.append(j)\n",
    "            if len(del_column_num_list) == 45:\n",
    "                del_column_num_list = np.delete(np.arange(0,45,1), int(recall_change_level_each_bin.reset_index(drop=True).idxmax()))\n",
    "        else:\n",
    "            pass\n",
    "       \n",
    "        j += 1\n",
    "    \n",
    "    del_dim_num = len(del_column_num_list)\n",
    "        \n",
    "    tmp_df = pd.DataFrame(data=[{\n",
    "                                'subject_ID': subject_ID, 'Corr_max_threshold': valid_value, 'del_dim_num': del_dim_num,\n",
    "                                'recall_change_level_each_bin_ave': recall_change_level_each_bin.mean(),\n",
    "                                'recall_change_level_delta': recall_change_level_each_bin[np.arange(0,3,1)].mean(),\n",
    "                                'recall_change_level_theta': recall_change_level_each_bin[np.arange(3,6,1)].mean(),\n",
    "                                'recall_change_level_alpha': recall_change_level_each_bin[np.arange(7,12,1)].mean(),\n",
    "                                'recall_change_level_beta': recall_change_level_each_bin[np.arange(12,29,1)].mean(),\n",
    "                                'recall_change_level_gamma': recall_change_level_each_bin[np.arange(29,45,1)].mean(),\n",
    "                                }])\n",
    "    \n",
    "    #sect_feat_bin = np.arange(0,3,1)   ##### delta     frequency corresponded to IM00-IM02 1 < w < 4\n",
    "    #sect_feat_bin = np.arange(3,6,1)   ##### theta     frequency corresponded to IM03-IM05 4 < w < 7\n",
    "    #sect_feat_bin = np.arange(7,12,1)   ##### alpha    frequency corresponded to IM07-IM11 8 < w < 13\n",
    "    #sect_feat_bin = np.arange(12,29,1) ##### beta      frequency corresponded to IM12-IM28 13 < w < 30\n",
    "    #sect_feat_bin = np.arange(29,45,1) ##### gamma     frequency corresponded to IM29-IM44 30 < w < 45\n",
    "    \n",
    "    del_dim_num_list_df = pd.concat([del_dim_num_list_df, tmp_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "del_dim_num_list_df.to_csv(f'../../project-ACII2024/paper_result/del_dim_num_list_df.csv', index=False)\n",
    "\n",
    "cm = 1/2.54  # centimeters in inches\n",
    "\n",
    "plt.figure(figsize=(8*cm, 6.5*cm))\n",
    "# 最適な閾値（最も相関係数が高い閾値）において削除する次元が多い人ほど，元々の性能が低い　pvalue=0.055\n",
    "plt.scatter(threshold_list_df['Corr_max_threshold'], threshold_list_df['Rs_NONE'])\n",
    "plt.show()\n",
    "print(spearmanr(threshold_list_df['Corr_max_threshold'], threshold_list_df['Rs_NONE']))\n",
    "\n",
    "plt.figure(figsize=(8*cm, 6.5*cm))\n",
    "# 最適な閾値（最も相関係数が高い閾値）での\"実際の最適な閾値での削除次元数と，元々の性能の相関　pvalue=0.016\n",
    "plt.scatter(del_dim_num_list_df['del_dim_num'], threshold_list_df['Rs_NONE'])\n",
    "plt.show()\n",
    "print(spearmanr(del_dim_num_list_df['del_dim_num'], threshold_list_df['Rs_NONE']))\n",
    "\n",
    "plt.figure(figsize=(8*cm, 6.5*cm))\n",
    "# \"実際の最適な閾値での削除次元数\"と，性能改善の相関　pvalue=0.013\n",
    "plt.scatter(del_dim_num_list_df['del_dim_num'], threshold_list_df['Corr_max_optimized'] - threshold_list_df['Rs_NONE'])\n",
    "plt.show()\n",
    "print(spearmanr(del_dim_num_list_df['del_dim_num'], threshold_list_df['Corr_max_optimized'] - threshold_list_df['Rs_NONE']))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8*cm, 6.5*cm))\n",
    "# 元々の性能（相関係数）と性能改善は強い負相関 P < 0.001\n",
    "plt.scatter(threshold_list_df['Rs_NONE'], threshold_list_df['Corr_max_optimized'] - threshold_list_df['Rs_NONE'])\n",
    "plt.show()\n",
    "print(spearmanr(threshold_list_df['Rs_NONE'], threshold_list_df['Corr_max_optimized'] - threshold_list_df['Rs_NONE']))\n",
    "\n",
    "plt.figure(figsize=(8*cm, 6.5*cm))\n",
    "\n",
    "plt.scatter(45-del_dim_num_list_df['del_dim_num'], threshold_list_df['Corr_max_threshold'])\n",
    "plt.show()\n",
    "print(spearmanr(45-del_dim_num_list_df['del_dim_num'], threshold_list_df['Corr_max_threshold']))\n",
    "\n",
    "\n",
    "# # 元々の性能（相関係数）と平均相対変化度は正相関方向だが有意差なし P < 0.13\n",
    "# plt.figure(figsize=(8.5*cm, 6*cm))\n",
    "# plt.scatter(del_dim_num_list_df['recall_change_level_each_bin_ave'], threshold_list_df['Rs_NONE'])\n",
    "# plt.show()\n",
    "# print(spearmanr(del_dim_num_list_df['recall_change_level_each_bin_ave'], threshold_list_df['Rs_NONE']))\n",
    "# del_dim_num_list_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corr between rec/res ration and Optimized number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AVE')\n",
    "plt.figure(figsize=(8.5*cm, 6*cm))\n",
    "# \"ラベルを使用することで求められる最適な閾値での削除次元数\"をラベル無しでどのように求めるか\n",
    "# \"実際の最適な閾値での削除次元数\"と平均相対変化度は有意に負相関 pvalue=0.011\n",
    "plt.scatter(del_dim_num_list_df['recall_change_level_each_bin_ave'], del_dim_num_list_df['del_dim_num'])\n",
    "plt.show()\n",
    "print(spearmanr(del_dim_num_list_df['recall_change_level_each_bin_ave'], del_dim_num_list_df['del_dim_num']))\n",
    "print('\"実際の最適な閾値での削除次元数\"と平均相対変化度は有意に負相関 pvalue=0.011')\n",
    "\n",
    "plt.figure(figsize=(8.5*cm, 6*cm))\n",
    "print()\n",
    "print('delta')\n",
    "plt.scatter(del_dim_num_list_df['recall_change_level_delta'], del_dim_num_list_df['del_dim_num'])\n",
    "plt.show()\n",
    "print(spearmanr(del_dim_num_list_df['recall_change_level_delta'], del_dim_num_list_df['del_dim_num']))\n",
    "\n",
    "plt.figure(figsize=(8.5*cm, 6*cm))\n",
    "print()\n",
    "print('theta')\n",
    "plt.scatter(del_dim_num_list_df['recall_change_level_theta'], del_dim_num_list_df['del_dim_num'])\n",
    "plt.show()\n",
    "print(spearmanr(del_dim_num_list_df['recall_change_level_theta'], del_dim_num_list_df['del_dim_num']))\n",
    "\n",
    "plt.figure(figsize=(8.5*cm, 6*cm))\n",
    "print()\n",
    "print('alpha')\n",
    "plt.scatter(del_dim_num_list_df['recall_change_level_alpha'], del_dim_num_list_df['del_dim_num'])\n",
    "plt.show()\n",
    "print(spearmanr(del_dim_num_list_df['recall_change_level_alpha'], del_dim_num_list_df['del_dim_num']))\n",
    "\n",
    "plt.figure(figsize=(8.5*cm, 6*cm))\n",
    "print()\n",
    "print('beta')\n",
    "plt.scatter(del_dim_num_list_df['recall_change_level_beta'], del_dim_num_list_df['del_dim_num'])\n",
    "plt.show()\n",
    "print(spearmanr(del_dim_num_list_df['recall_change_level_beta'], del_dim_num_list_df['del_dim_num']))\n",
    "\n",
    "plt.figure(figsize=(8.5*cm, 6*cm))\n",
    "print()\n",
    "print('gamma')\n",
    "plt.scatter(del_dim_num_list_df['recall_change_level_gamma'], del_dim_num_list_df['del_dim_num'])\n",
    "plt.show()\n",
    "print(spearmanr(np.log(del_dim_num_list_df['recall_change_level_gamma']), del_dim_num_list_df['del_dim_num']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of del_dim_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    \n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "#tmp_df = del_dim_num_list_df.loc[:, 'recall_change_level_beta':'recall_change_level_gamma']\n",
    "tmp_df = del_dim_num_list_df.reindex(columns=['recall_change_level_each_bin_ave', 'recall_change_level_beta', 'recall_change_level_gamma'])\n",
    "\n",
    "pred_df = del_dim_num_list_df.reindex(columns=['subject_ID', 'del_dim_num'])\n",
    "pred_df = pd.concat([pred_df, tmp_df], axis=1)\n",
    "#pred_df['age'] = del_dim_num_list_df['subject_ID'].str[-4:-2].astype(int) / 100\n",
    "#pred_df['sex'] = np.concatenate([np.ones(16), np.zeros(14)])\n",
    "\n",
    "pred_del_dim_list = []\n",
    "y = []\n",
    "for subject_ID in subject_ID_list:\n",
    "\n",
    "    train_QUE = 'subject_ID != ' + '\\\"' + subject_ID + '\\\"' \n",
    "    test_QUE = 'subject_ID == ' + '\\\"' + subject_ID + '\\\"'\n",
    "                       \n",
    "    train_df = pred_df.query(train_QUE)\n",
    "    test_df = pred_df.query(test_QUE)\n",
    "    \n",
    "    X_train = train_df.iloc[:, 2:].values\n",
    "    y_train = train_df['del_dim_num'].values\n",
    "    X_test = test_df.iloc[:, 2:].values\n",
    "    y_test = test_df['del_dim_num'].values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    if subject_ID == subject_ID_list[0]:\n",
    "        print('X_train.shape', np.shape(X_train), 'y_train.shape', np.shape(y_train), 'X_test.shape', np.shape(X_test), 'y_test.shape', np.shape(y_test))\n",
    "    \n",
    "    #regr =  MLPRegressor(hidden_layer_sizes=(5,), activation='relu', solver='adam', alpha=0.01, learning_rate_init=1, random_state=0, early_stopping=True, validation_fraction=0.1)\n",
    "    \n",
    "    #regr = GridSearchCV(SVR(kernel='rbf', max_iter=1000), cv=3, param_grid=tuned_parameters, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    \n",
    "    tuned_parameters = [{'hidden_layer_sizes':[(5,)], 'alpha': [0.001, 0.01, 0.1, 1], 'learning_rate_init':[0.001, 0.01, 0.1, 1]}]\n",
    "    regr = GridSearchCV(MLPRegressor(activation='relu', solver='adam', random_state=0, early_stopping=True, validation_fraction=0.1, max_iter=1000),\n",
    "                        cv=3, param_grid=tuned_parameters, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    \n",
    "    # hidden_layer_sizes=(5,)\n",
    "    \n",
    "    regr.fit(X_train, y_train)\n",
    "    print(regr.best_params_)\n",
    "    best = regr.best_estimator_\n",
    "    pred_del_dim = np.ceil(best.predict(X_test))\n",
    "    \n",
    "    # tuned_parameters = [{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],'epsilon': np.arange(0,1.1,0.5)}]\n",
    "    # regr = GridSearchCV(SVR(kernel='rbf', max_iter=1000), cv=3, param_grid=tuned_parameters, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    # regr.fit(X_train, y_train)\n",
    "    # #print(regr.best_params_)\n",
    "    # best = regr.best_estimator_\n",
    "    # pred_del_dim = best.predict(X_test)\n",
    "        \n",
    "    pred_del_dim_list.append(pred_del_dim[-1])\n",
    "    y.append(y_test)\n",
    "    \n",
    "pred_del_dim_list = np.where(np.array(pred_del_dim_list) < 0, 0, pred_del_dim_list)\n",
    "pred_del_dim_list = np.where(np.array(pred_del_dim_list) > 44,44, pred_del_dim_list)\n",
    "\n",
    "#pred_del_dim_list_a = pred_del_dim_list\n",
    "#pred_del_dim_list_b = pred_del_dim_list\n",
    "#pred_del_dim_list_c = pred_del_dim_list\n",
    "    \n",
    "print(pearsonr(pred_del_dim_list, np.ravel(y)))\n",
    "del_dim_num_list_df['pred_del_dim'] = pred_del_dim_list\n",
    "plt.scatter(pred_del_dim_list, np.ravel(y))\n",
    "plt.scatter(np.arange(0,45,1), np.arange(0,45,1))\n",
    "plt.show()\n",
    "del_dim_num_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.81 / 0.22\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.svm import LinearSVR\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.cross_decomposition import PLSRegression\n",
    "# from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# tmp_df = del_dim_num_list_df.loc[:, 'recall_change_level_delta':'recall_change_level_gamma']\n",
    "# tmp_df\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(recall_change_level_each_bin_df)\n",
    "# scale_df = pd.DataFrame(scaler.transform(recall_change_level_each_bin_df))\n",
    "\n",
    "# pred_df = del_dim_num_list_df.reindex(columns=['subject_ID', 'del_dim_num'])\n",
    "# pred_df = pd.concat([pred_df, tmp_df], axis=1)\n",
    "\n",
    "# pred_del_dim_list = []\n",
    "# for subject_ID in subject_ID_list:\n",
    "\n",
    "#     train_QUE = 'subject_ID != ' + '\\\"' + subject_ID + '\\\"' \n",
    "#     test_QUE = 'subject_ID == ' + '\\\"' + subject_ID + '\\\"'\n",
    "                       \n",
    "#     train_df = pred_df.query(train_QUE)\n",
    "#     test_df = pred_df.query(test_QUE)\n",
    "    \n",
    "#     X_train = train_df.iloc[:, 2:].values\n",
    "#     y_train = train_df['del_dim_num'].values\n",
    "#     X_test = test_df.iloc[:, 2:].values\n",
    "#     y_test = test_df['del_dim_num'].values\n",
    "    \n",
    "#     if subject_ID == subject_ID_list[0]:\n",
    "#         print('X_train.shape', np.shape(X_train), 'y_train.shape', np.shape(y_train), 'X_test.shape', np.shape(X_test), 'y_test.shape', np.shape(y_test))\n",
    "    \n",
    "#     # regr =  SVR()\n",
    "#     # regr.fit(X_train, y_train)\n",
    "#     # pred_del_dim = np.ceil(regr.predict(X_test))\n",
    "    \n",
    "#     tuned_parameters = [{'C': [0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "#     regr = GridSearchCV(SVR(kernel='rbf', max_iter=1000), cv=3, param_grid=tuned_parameters, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "#     regr.fit(X_train, y_train)\n",
    "#     #print(regr.best_params_)\n",
    "#     best = regr.best_estimator_\n",
    "#     pred_del_dim = best.predict(X_test)\n",
    "        \n",
    "#     pred_del_dim_list.append(pred_del_dim[-1])\n",
    "    \n",
    "# print(pearsonr(pred_del_dim_list, pred_df['del_dim_num']))\n",
    "# del_dim_num_list_df['pred_del_dim'] = pred_del_dim_list\n",
    "# del_dim_num_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.83 / 0.24\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.svm import LinearSVR\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.cross_decomposition import PLSRegression\n",
    "# from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# tmp_df = del_dim_num_list_df.loc[:, 'recall_change_level_delta':'recall_change_level_gamma']\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# # scaler.fit(tmp_df)\n",
    "# # tmp_df = pd.DataFrame(scaler.transform(tmp_df))\n",
    "\n",
    "# pred_df = del_dim_num_list_df.reindex(columns=['subject_ID', 'del_dim_num'])\n",
    "# pred_df = pd.concat([pred_df, tmp_df], axis=1)\n",
    "\n",
    "# pred_del_dim_list = []\n",
    "# y = []\n",
    "# for subject_ID in subject_ID_list:\n",
    "\n",
    "#     train_QUE = 'subject_ID != ' + '\\\"' + subject_ID + '\\\"' \n",
    "#     test_QUE = 'subject_ID == ' + '\\\"' + subject_ID + '\\\"'\n",
    "                       \n",
    "#     train_df = pred_df.query(train_QUE)\n",
    "#     test_df = pred_df.query(test_QUE)\n",
    "    \n",
    "#     X_train = train_df.iloc[:, 2:].values\n",
    "#     y_train = train_df['del_dim_num'].values\n",
    "#     X_test = test_df.iloc[:, 2:].values\n",
    "#     y_test = test_df['del_dim_num'].values\n",
    "    \n",
    "#     if subject_ID == subject_ID_list[0]:\n",
    "#         print('X_train.shape', np.shape(X_train), 'y_train.shape', np.shape(y_train), 'X_test.shape', np.shape(X_test), 'y_test.shape', np.shape(y_test))\n",
    "    \n",
    "#     # regr =  SVR()\n",
    "#     # regr.fit(X_train, y_train)\n",
    "#     # pred_del_dim = np.ceil(regr.predict(X_test))\n",
    "    \n",
    "#     tuned_parameters = [{'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'epsilon': np.arange(0, 3, 0.01)}]\n",
    "#     regr = GridSearchCV(SVR(kernel='rbf', max_iter=10000), cv=3, param_grid=tuned_parameters, scoring='r2', n_jobs=-1)\n",
    "#     regr.fit(X_train, y_train)\n",
    "#     #print(regr.best_params_)\n",
    "#     best = regr.best_estimator_\n",
    "#     pred_del_dim = best.predict(X_test)\n",
    "        \n",
    "#     pred_del_dim_list.append(pred_del_dim[-1])\n",
    "#     y.append(y_test)\n",
    "    \n",
    "# print(pearsonr(pred_del_dim_list, np.ravel(y)))\n",
    "# del_dim_num_list_df['pred_del_dim'] = pred_del_dim_list\n",
    "# plt.scatter(pred_del_dim_list, np.ravel(y))\n",
    "# plt.show()\n",
    "# del_dim_num_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # 0.84 / 0.28\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.svm import LinearSVR\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.cross_decomposition import PLSRegression\n",
    "# from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# #tmp_df = del_dim_num_list_df.loc[:, 'recall_change_level_beta':'recall_change_level_gamma']\n",
    "# tmp_df = del_dim_num_list_df.reindex(columns=['recall_change_level_each_bin_ave', 'recall_change_level_beta', 'recall_change_level_gamma'])\n",
    "\n",
    "\n",
    "\n",
    "# pred_df = del_dim_num_list_df.reindex(columns=['subject_ID', 'del_dim_num'])\n",
    "# pred_df = pd.concat([pred_df, tmp_df], axis=1)\n",
    "# #pred_df['age'] = del_dim_num_list_df['subject_ID'].str[-4:-2].astype(int) / 100\n",
    "\n",
    "# pred_del_dim_list = []\n",
    "# y = []\n",
    "# for subject_ID in subject_ID_list:\n",
    "\n",
    "#     train_QUE = 'subject_ID != ' + '\\\"' + subject_ID + '\\\"' \n",
    "#     test_QUE = 'subject_ID == ' + '\\\"' + subject_ID + '\\\"'\n",
    "                       \n",
    "#     train_df = pred_df.query(train_QUE)\n",
    "#     test_df = pred_df.query(test_QUE)\n",
    "    \n",
    "#     X_train = train_df.iloc[:, 2:].values\n",
    "#     y_train = train_df['del_dim_num'].values\n",
    "#     X_test = test_df.iloc[:, 2:].values\n",
    "#     y_test = test_df['del_dim_num'].values\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(X_train)\n",
    "#     X_train = scaler.transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "    \n",
    "#     if subject_ID == subject_ID_list[0]:\n",
    "#         print('X_train.shape', np.shape(X_train), 'y_train.shape', np.shape(y_train), 'X_test.shape', np.shape(X_test), 'y_test.shape', np.shape(y_test))\n",
    "    \n",
    "#     #regr =  MLPRegressor(hidden_layer_sizes=(5,), activation='relu', solver='adam', alpha=0.01, learning_rate_init=1, random_state=0, early_stopping=True, validation_fraction=0.1)\n",
    "    \n",
    "#     #regr = GridSearchCV(SVR(kernel='rbf', max_iter=1000), cv=3, param_grid=tuned_parameters, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    \n",
    "#     tuned_parameters = [{'alpha': [0.0001, 0.001, 0.01, 0.1, 1],'learning_rate_init':[0.01, 0.1, 1] }]\n",
    "#     regr = GridSearchCV(MLPRegressor(hidden_layer_sizes=(5,), activation='relu', solver='adam', random_state=0, early_stopping=True, validation_fraction=0.1, max_iter=1000),\n",
    "#                         cv=3, param_grid=tuned_parameters, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    \n",
    "#     regr.fit(X_train, y_train)\n",
    "#     #print(regr.best_params_)\n",
    "#     best = regr.best_estimator_\n",
    "#     pred_del_dim = np.ceil(best.predict(X_test))\n",
    "    \n",
    "#     # tuned_parameters = [{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],'epsilon': np.arange(0,1.1,0.5)}]\n",
    "#     # regr = GridSearchCV(SVR(kernel='rbf', max_iter=1000), cv=3, param_grid=tuned_parameters, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "#     # regr.fit(X_train, y_train)\n",
    "#     # #print(regr.best_params_)\n",
    "#     # best = regr.best_estimator_\n",
    "#     # pred_del_dim = best.predict(X_test)\n",
    "        \n",
    "#     pred_del_dim_list.append(pred_del_dim[-1])\n",
    "#     y.append(y_test)\n",
    "    \n",
    "# pred_del_dim_list = np.where(np.array(pred_del_dim_list) < 0, 0, pred_del_dim_list)\n",
    "# pred_del_dim_list = np.where(np.array(pred_del_dim_list) > 44,44, pred_del_dim_list)\n",
    "    \n",
    "# print(pearsonr(pred_del_dim_list, np.ravel(y)))\n",
    "# del_dim_num_list_df['pred_del_dim'] = pred_del_dim_list\n",
    "# plt.scatter(pred_del_dim_list, np.ravel(y))\n",
    "# plt.scatter(np.arange(0,45,1), np.arange(0,45,1))\n",
    "# plt.show()\n",
    "# del_dim_num_list_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Late fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = timestr\n",
    "combination_list = []\n",
    "for n in range(1,len(modality_list)+1):\n",
    "\tfor comb in itertools.combinations(modality_list, n):\n",
    "\t    combination_list.append(list(comb))\n",
    "late_fusion_list = [s for s in combination_list] # if not s in [[modality_list[0]], [modality_list[1]], [modality_list[2]]]] # use if there are modalities you don't want to fuse\n",
    "\n",
    "dependency = dep_list[-1]\n",
    "task_name = task_list[-1]\n",
    "eval_name_list = eval_list[-1]\n",
    "label_name = label_name_list[-1]\n",
    "fusion_method = 'ensemble'\n",
    "ml_mod = 'ensemble_model'\n",
    "\n",
    "for modal_comb in late_fusion_list:\n",
    "    if len(modal_comb) == 1: # omit unimodal\n",
    "        continue\n",
    "    for subject_ID in subject_ID_list:\n",
    "        for rep_exp_num in range(rep_exp):\n",
    "            rep_exp_num += 1\n",
    "            modal_count_i = 0\n",
    "            \n",
    "            for modal in modal_comb:\n",
    "                if modal == 'IM':\n",
    "                    modal_dir = 'bin_sect_thres_v2'\n",
    "                else:\n",
    "                    modal_dir = '[\\''  + modal + '\\']'\n",
    "                proba_csv_path = f'../ML_results/dummy/reg_pred/{timestr}/{subject_ID}/{label_name}/{modal_dir}/SVM/uni/rep_exp_num_{rep_exp_num}.csv'\n",
    "                tmp_proba_df = pd.read_csv(f'{proba_csv_path}')\n",
    "\n",
    "                tmp_pred_ar = tmp_proba_df['y_pred'].values\n",
    "                \n",
    "                if modal_count_i == 0:\n",
    "                    y_pred_ar = tmp_pred_ar\n",
    "                    modal_count_i += 1\n",
    "                else:\n",
    "                    y_pred_ar = y_pred_ar + tmp_pred_ar # adding each modal prediction value\n",
    "                    modal_count_i += 1\n",
    "                    \n",
    "            info_dict = {'subject_ID': subject_ID, 'dependency': dependency, 'task_name': task_name,\n",
    "                        'label_name': label_name, 'modal_comb': modal_comb, 'ml_mod': ml_mod,\n",
    "                        'fusion_method': fusion_method, 'rep_exp_num': rep_exp_num, 'f1_setting': None,\n",
    "                        'timestr': timestr, 'elapsed': None,\n",
    "                        'valid_target': 'bin_sect_thres'\n",
    "                        }\n",
    "\n",
    "            y_pred = y_pred_ar / len(modal_comb) # averaging the prediction value\n",
    "            y_true = tmp_proba_df['y_true'].values\n",
    "            \n",
    "            print('rep_exp_num:', rep_exp_num, ', modal_count:', modal_count_i, modal_comb, 'y_pred', np.round(y_pred, decimals=1), 'y_true', y_true)\n",
    "            \n",
    "            save_pred_and_prob(task_name, None, y_pred, y_true, info_dict)\n",
    "            \n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            if len(np.unique(y_true)) == 1:\n",
    "                r2, rp, rq = np.nan, np.nan, np.nan\n",
    "            else:\n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                rp = pearsonr(y_true, y_pred)[0]\n",
    "                rs = spearmanr(y_true, y_pred)[0]\n",
    "                \n",
    "            reg_evalist = [mae, r2, rp, rs]\n",
    "            print('test_MAE:', np.round(mae, decimals=3), f'test_R2:', np.round(r2, decimals=3), end=' ')\n",
    "            print('test_Rp:', np.round(rp, decimals=3), f'test_Rs:', np.round(rs, decimals=3))\n",
    "            print()\n",
    "            \n",
    "            save_cls_or_reg(reg_evalist, eval_name_list, info_dict, rep_exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
